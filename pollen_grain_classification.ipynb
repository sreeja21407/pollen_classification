{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31294875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# Define the root dataset path\n",
    "path = r\"C:\\Users\\Hp\\Music\\music\\pollen_classification\\pollen_classification\\dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7faa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all .jpg files from subdirectories\n",
    "image_paths = []\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(\".jpg\"):\n",
    "            image_paths.append(os.path.join(root, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume folder name is the class (i.e., path/.../<class_name>/image.jpg)\n",
    "names = [os.path.basename(os.path.dirname(img_path)) for img_path in image_paths]\n",
    "classes = Counter(names)\n",
    "print(\"Number of images:\", len(image_paths))\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.title('Class Counts in Dataset')\n",
    "plt.bar(*zip(*classes.items()))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_class = {key: [] for key in classes.keys()}\n",
    "for img_path in image_paths:\n",
    "    key = os.path.basename(os.path.dirname(img_path))\n",
    "    path_class[key].append(img_path)\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i, key in enumerate(path_class.keys()):\n",
    "    for j in range(min(3, len(path_class[key]))):\n",
    "        img = Image.open(path_class[key][j])\n",
    "        ax = fig.add_subplot(len(path_class), 3, 3*i + j + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(img)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(key, rotation=0, size='large', labelpad=40)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a731d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "size = []\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(\".jpg\"):\n",
    "            img_path = os.path.join(root, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                size.append(img.shape)\n",
    "\n",
    "x, y, _ = zip(*size)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x, y, alpha=0.6)\n",
    "plt.title(\"Image Size Scatterplot\")\n",
    "plt.xlabel(\"Height\")\n",
    "plt.ylabel(\"Width\")\n",
    "plt.grid(True)\n",
    "plt.plot([0, 800], [0, 800], 'r')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295e984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre processing\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def process_img(img, size=(128, 128)):\n",
    "    # Convert BGR to RGB since cv2 reads in BGR format\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Resize and normalize\n",
    "    img_resized = cv2.resize(img_rgb, size)\n",
    "    return img_resized.astype(np.float32) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ea0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED: Collect data with consistent class labeling\n",
    "X, Y = [], []\n",
    "valid_extensions = ['.jpg', '.jpeg', '.png']\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    # Skip the root directory itself\n",
    "    if root == path:\n",
    "        continue\n",
    "    \n",
    "    for file in files:\n",
    "        if any(file.lower().endswith(ext) for ext in valid_extensions):\n",
    "            img_path = os.path.join(root, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                try:\n",
    "                    processed_img = process_img(img)\n",
    "                    X.append(processed_img)\n",
    "                    # Use the immediate parent directory as class label\n",
    "                    class_name = os.path.basename(root)\n",
    "                    Y.append(class_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "print(f\"Total images loaded: {len(X)}\")\n",
    "print(f\"Classes found: {set(Y)}\")\n",
    "print(f\"Class distribution: {Counter(Y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac654c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# FIXED: Proper label encoding\n",
    "le = LabelEncoder()\n",
    "Y_encoded = le.fit_transform(Y)\n",
    "num_classes = len(le.classes_)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Class mapping: {dict(zip(le.classes_, range(num_classes)))}\")\n",
    "\n",
    "# FIXED: Stratified split with proper test size\n",
    "X_train, X_test, Y_train_encoded, Y_test_encoded = train_test_split(\n",
    "    X, Y_encoded, \n",
    "    test_size=0.2,  # More reasonable test size\n",
    "    stratify=Y_encoded,\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Convert to categorical\n",
    "Y_train = to_categorical(Y_train_encoded, num_classes)\n",
    "Y_test = to_categorical(Y_test_encoded, num_classes)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Training labels shape: {Y_train.shape}\")\n",
    "print(f\"Test labels shape: {Y_test.shape}\")\n",
    "\n",
    "# Print class distribution\n",
    "unique_train, counts_train = np.unique(Y_train_encoded, return_counts=True)\n",
    "unique_test, counts_test = np.unique(Y_test_encoded, return_counts=True)\n",
    "print(\"Training set class distribution:\", dict(zip(unique_train, counts_train)))\n",
    "print(\"Test set class distribution:\", dict(zip(unique_test, counts_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c757bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Make sure Y is defined (you've already collected it during preprocessing)\n",
    "print(\"Sample class labels:\", Y[:5])  # Debug: check first few labels\n",
    "\n",
    "# Step 1: Encode labels (folder names)\n",
    "label_encoder = LabelEncoder()\n",
    "Y_encoded = label_encoder.fit_transform(Y)  # FIXED: use Y, not label\n",
    "\n",
    "# Step 2: One-hot encode the labels\n",
    "Y_onehot = to_categorical(Y_encoded)\n",
    "\n",
    "# Step 3: Split into training and testing data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Get class indices for computing weights\n",
    "Y_train_encoded = np.argmax(Y_train, axis=1)\n",
    "\n",
    "# Step 5: Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(Y_train_encoded),\n",
    "    y=Y_train_encoded\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa39eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# FIXED: Improved model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# First block\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=X_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Second block\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Third block\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fourth block (optional, remove if overfitting)\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Classifier\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a96039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED: Better optimizer settings\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),  # Start with higher learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# FIXED: More conservative data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,        # Reduced rotation\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'       # Better fill mode\n",
    ")\n",
    "\n",
    "# FIXED: Add callbacks for better training\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=0.0001,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Fit the data generator\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# FIXED: Better training parameters\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, Y_train, batch_size=32),\n",
    "    steps_per_epoch=len(X_train) // 32,\n",
    "    epochs=100,  # Reduced epochs, let early stopping handle it\n",
    "    validation_data=(X_test, Y_test),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6471858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "\n",
    "# FIXED: Save model with better naming\n",
    "model.save(\"pollen_classification_model.h5\")\n",
    "print(\"Model saved as pollen_classification_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7fd14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED: Save label encoder for future predictions\n",
    "import pickle\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "print(\"Label encoder saved as label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0a2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbfb456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED: Add prediction function for testing\n",
    "def predict_image(model, image_path, label_encoder):\n",
    "    \"\"\"\n",
    "    Predict the class of a single image\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Preprocess the image the same way as training data\n",
    "    processed_img = process_img(img)\n",
    "    img_batch = np.expand_dims(processed_img, axis=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_batch, verbose=0)\n",
    "    predicted_class_idx = np.argmax(predictions[0])\n",
    "    confidence = np.max(predictions[0])\n",
    "    predicted_class = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "    \n",
    "    return predicted_class, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c013cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction on a few images\n",
    "print(\"\\nTesting predictions on some images:\")\n",
    "for i, img_path in enumerate(image_paths[:5]):  # Test first 5 images\n",
    "    true_class = os.path.basename(os.path.dirname(img_path))\n",
    "    pred_class, confidence = predict_image(model, img_path, le)\n",
    "    print(f\"Image: {os.path.basename(img_path)}\")\n",
    "    print(f\"True class: {true_class}, Predicted: {pred_class}, Confidence: {confidence:.4f}\")\n",
    "    print(\"---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
